{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Burr RAG with LanceDB and dlt document ingestion\n",
    "\n",
    "This example shows how to build a chatbot with RAG over Substack blogs (or any RSS feed) stored into LanceDB. \n",
    "\n",
    "The stack includes:\n",
    "\n",
    "- Burr\n",
    "- LanceDB\n",
    "- dlt\n",
    "- OpenAI\n",
    "- OpenTelemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `Substack -> LanceDB` ingestion with `dlt`\n",
    "\n",
    "To ingest data, we use [dlt and its LanceDB integration](https://dlthub.com/devel/dlt-ecosystem/destinations/lancedb), which makes it very simple to query, embed, and store blogs from the web into LanceDB tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Text processing\n",
    "\n",
    "First, we define simple functions to split long text strings into sentences and a way to assemble sentences into larger context windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_text(text):\n",
    "    \"\"\"Split text on punction (., !, ?).\"\"\"\n",
    "    sentence_endings = r'[.!?]+'\n",
    "    for sentence in re.split(sentence_endings, text):\n",
    "        sentence = sentence.strip()\n",
    "        if sentence:\n",
    "            yield sentence\n",
    "\n",
    "\n",
    "def contextualize(chunks: list[str], window=5, stride=3, min_window_size=2):\n",
    "    \"\"\"Rolling window operation to join consecutive sentences into larger chunks.\"\"\"\n",
    "    n_chunks = len(chunks)\n",
    "    for start_i in range(0, n_chunks, stride):\n",
    "        if (start_i + window <= n_chunks) or (n_chunks - start_i >= min_window_size):\n",
    "            yield \" \".join(chunks[start_i : min(start_i + window, n_chunks)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define `dlt` resources\n",
    "\n",
    "To use `dlt`, you author `Resource` objects that generate data using the `@dlt.resource` decorator. In this case, we create a resource that pulls an RSS feed from a Substack blog URL using the `requests` and `feedparser` libraries. Then, we iterate over RSS entries and yield them as dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "\n",
    "import requests\n",
    "import feedparser\n",
    "import dlt\n",
    "\n",
    "@dlt.resource(name=\"substack\", write_disposition=\"merge\", primary_key=\"id\")\n",
    "def rss_entries(substack_url: str) -> Generator:\n",
    "    \"\"\"Substack blog entries retrieved from a RSS feed\"\"\"\n",
    "    FIELDS_TO_EXCLUDE = [\n",
    "        \"published_parsed\",\n",
    "        \"title_detail\",\n",
    "        \"summary_detail\",\n",
    "        \"author_detail\",\n",
    "        \"guidislink\",\n",
    "        \"authors\",\n",
    "        \"links\"\n",
    "    ]\n",
    "\n",
    "    r = requests.get(f\"{substack_url}/feed\")\n",
    "    rss_feed = feedparser.parse(r.content)\n",
    "    for entry in rss_feed[\"entries\"]:\n",
    "        for field in FIELDS_TO_EXCLUDE:\n",
    "            entry.pop(field)\n",
    "\n",
    "        yield entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use `@dlt.transformer` to define operations on the values returned by `Resource` objects. In this case, we define three transformations that we'll chain:\n",
    "\n",
    "1. Parse HTML into a string stripped of tags\n",
    "2. Chunk the text string by splitting it into sentences\n",
    "3. Join sentence chunks into larger \"context windows\" via a rolling operation.\n",
    "\n",
    "We use a custom trick to map and store the relationship between HTML pages, sentence chunks, and context windows ([learn more](\"https://github.com/dlt-hub/dlt/issues/1699\"))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import utils\n",
    "\n",
    "\n",
    "@dlt.transformer(primary_key=\"id\")\n",
    "def parsed_html(rss_entry: dict):\n",
    "    \"\"\"Parse the HTML from the RSS entry\"\"\"\n",
    "    soup = BeautifulSoup(rss_entry[\"content\"][0][\"value\"], \"html.parser\")\n",
    "    parsed_text = soup.get_text(separator=\" \", strip=True)\n",
    "    yield {\"id\": rss_entry[\"id\"], \"text\": parsed_text}\n",
    "\n",
    "\n",
    "@dlt.transformer(primary_key=\"chunk_id\")\n",
    "def chunks(parsed_html: dict) -> list[dict]:\n",
    "    \"\"\"Chunk text\"\"\"\n",
    "    return [\n",
    "        dict(\n",
    "            document_id=parsed_html[\"id\"],\n",
    "            chunk_id=idx,\n",
    "            text=text,\n",
    "        )\n",
    "        for idx, text in enumerate(split_text(parsed_html[\"text\"]))\n",
    "    ]\n",
    "\n",
    "# order is important for reduce / rolling step\n",
    "# default to order of the batch or specifying sorting key\n",
    "@dlt.transformer(primary_key=\"context_id\")\n",
    "def contexts(chunks: list[dict]) -> Generator:\n",
    "    \"\"\"Assemble consecutive chunks into larger context windows\"\"\"\n",
    "    # first handle the m-to-n relationship\n",
    "    # set of foreign keys (i.e., \"chunk_id\")\n",
    "    chunk_id_set = set(chunk[\"chunk_id\"] for chunk in chunks)\n",
    "    context_id = utils.hash_set(chunk_id_set)\n",
    "    \n",
    "    # create a table only containing the keys\n",
    "    for chunk_id in chunk_id_set :\n",
    "        yield dlt.mark.with_table_name(\n",
    "            {\"chunk_id\": chunk_id, \"context_id\": context_id},\n",
    "            \"chunks_to_contexts_keys\",\n",
    "        ) \n",
    "    \n",
    "    # main transformation logic\n",
    "    for contextualized in contextualize([chunk[\"text\"] for chunk in chunks]):\n",
    "        yield dlt.mark.with_table_name(\n",
    "            {\"context_id\": context_id, \"text\": contextualized},\n",
    "            \"contexts\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Execute the pipeline\n",
    "\n",
    "Before ingesting data, we need to the configuration for the `dlt` destination (LanceDB in our case). We specify which OpenAI model we want to use for text embedding and store our API key.\n",
    "\n",
    "`dlt` provides [multiple ways to do so](https://dlthub.com/devel/general-usage/credentials), but using the `os` module is simply the most convenient for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# set your OpenAI API key\n",
    "openai_api_key = \n",
    "\n",
    "# this environment variable isn't needed by dlt, but we'll use it later\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL_PROVIDER\"] = \"openai\"\n",
    "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL\"] = \"text-embedding-3-small\"\n",
    "\n",
    "os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__URI\"] = \".lancedb\"\n",
    "os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__EMBEDDING_MODEL_PROVIDER_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine our Substack blog `Resource` with the different text processing `Transformer` using the pipe operator `|`. We also use the `lancedb_adapter` by `dlt` which allows to specify which field will be embed with the OpenAI embedding service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjean/projects/dagworks/burr/examples/rag-lancedb-ingestion/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dlt.destinations.adapters import lancedb_adapter\n",
    "import dlt.destinations.impl.lancedb.models\n",
    "\n",
    "blog_url = \"https://blog.dagworks.io/\"\n",
    "\n",
    "full_entries = lancedb_adapter(rss_entries(blog_url), embed=\"summary\")\n",
    "chunked_entries = rss_entries(blog_url) | parsed_html | chunks\n",
    "contextualized_chunks = lancedb_adapter(chunked_entries | contexts, embed=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create the `Pipeline` object and minimally specify a `pipeline_name` and `destination`. This won't exectue any code or ingest any data.\n",
    "\n",
    "Then, calling `pipeline.run()` with the `Resource` and `Transformer` objects will launch the ingestion job and return a `LoadInfo` object detailing the results of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"substack-blog\",\n",
    "    destination=\"lancedb\",\n",
    "    dataset_name=\"dagworks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline substack-blog load step completed in 5.06 seconds\n",
      "1 load package(s) were loaded to destination LanceDB and into dataset dagworks\n",
      "The LanceDB destination used <dlt.destinations.impl.lancedb.configuration.LanceDBCredentials object at 0x7f2626a4ead0> location to store data\n",
      "Load package 1724874594.4636345 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "load_info = pipeline.run([full_entries, chunked_entries, contextualized_chunks])\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Burr RAG with LanceDB memory\n",
    "Burr allows you to define an `Application` by defining a set of actions and valid transitions between them. This approach allows to define complex agents in an easy-to-understand and debug manner. \n",
    "\n",
    "Burr solves many challenges to productionize agents including monitoring, storing interactions, streaming, and more, and comes with a rich open-source UI for observability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Define `@action`\n",
    "\n",
    "First, we define actions the agent can take with the `@action` decorator. The function must take a `State` object as first argument and return a `State` object. The decorator specifies which `State` fields can be read from and written to.\n",
    "\n",
    "The next cell contains two actions:\n",
    "- `retrieve_relevant_chunks()` reads from the LanceDB table `dagworks___contexts` that was generated by `dlt` and retrieves the top 4 most similar rows to the `user_query` string. It writes the search results to the `relevant_chunks` state field and appends the user input to the `chat_history` state field.\n",
    "- `bot_turn()` reads the `chat_history` and the `relevant_chunks` from state, combine the text into a prompt and send a request to OpenAI. The LLM's response is appended to the `chat_history` state field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "import openai\n",
    "import lancedb\n",
    "\n",
    "from burr.core import State, action\n",
    "\n",
    "\n",
    "@action(reads=[], writes=[\"relevant_chunks\", \"chat_history\"])\n",
    "def retrieve_relevant_chunks(\n",
    "    state: State,\n",
    "    user_query: str,\n",
    "    lancedb_con: lancedb.DBConnection,\n",
    ") -> State:\n",
    "    \"\"\"Search LanceDB with the user query and return the top 4 results\"\"\"\n",
    "    # this is a table generated by `dlt`\n",
    "    text_chunks_table = lancedb_con.open_table(\"dagworks___contexts\")\n",
    "\n",
    "    search_results = (\n",
    "        text_chunks_table\n",
    "        .search(user_query)  # this automatically embed the query does vector search\n",
    "        .select([\"text\", \"id__\"])  # retrieve the `text` and `id__` columns\n",
    "        .limit(4)  # get the top 4 rows\n",
    "        .to_list()\n",
    "    )\n",
    "\n",
    "    return state.update(relevant_chunks=search_results).append(chat_history=user_query)\n",
    "\n",
    "\n",
    "@action(reads=[\"chat_history\", \"relevant_chunks\"], writes=[\"chat_history\"])\n",
    "def bot_turn(state: State, llm_client: openai.OpenAI) -> State:\n",
    "    \"\"\"Collect relevant chunks and produce a response to the user query\"\"\"\n",
    "    user_query = state[\"chat_history\"][-1]\n",
    "    relevant_chunks = state[\"relevant_chunks\"]\n",
    "\n",
    "    # create system and user prompts\n",
    "    system_prompt = textwrap.dedent(\n",
    "        \"\"\"You are a conversational agent designed to discuss and provide \\\n",
    "        insights about various blog posts. Your task is to engage users in \\\n",
    "        meaningful conversations based on the content of the blog articles they mention.\n",
    "        \"\"\"\n",
    "    )\n",
    "    joined_chunks = ' '.join([c[\"text\"] for c in relevant_chunks])\n",
    "    user_prompt = \"BLOGS CONTENT\\n\" + joined_chunks + \"\\nUSER QUERY\\n\" + user_query\n",
    "\n",
    "    # query the OpenAI API\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    bot_answer = response.choices[0].message.content\n",
    "\n",
    "    return state.append(chat_history=bot_answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assemble the `Application`\n",
    "To build a Burr `Application`, you need to pass it actions and define valid transitions as tuples  `(from, to)`. The application must also define an `entrypoint` from where to begin execution. Then, we can visualize the graph of possible states and actions.\n",
    "\n",
    "First, let's see the simplest `Application` definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"419pt\" height=\"177pt\"\n",
       " viewBox=\"0.00 0.00 418.50 177.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 173)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-173 414.5,-173 414.5,4 -4,4\"/>\n",
       "<!-- retrieve_relevant_chunks -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>retrieve_relevant_chunks</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M335.5,-103C335.5,-103 163.5,-103 163.5,-103 157.5,-103 151.5,-97 151.5,-91 151.5,-91 151.5,-78 151.5,-78 151.5,-72 157.5,-66 163.5,-66 163.5,-66 335.5,-66 335.5,-66 341.5,-66 347.5,-72 347.5,-78 347.5,-78 347.5,-91 347.5,-91 347.5,-97 341.5,-103 335.5,-103\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.5\" y=\"-80.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">retrieve_relevant_chunks</text>\n",
       "</g>\n",
       "<!-- bot_turn -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>bot_turn</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M277.5,-37C277.5,-37 221.5,-37 221.5,-37 215.5,-37 209.5,-31 209.5,-25 209.5,-25 209.5,-12 209.5,-12 209.5,-6 215.5,0 221.5,0 221.5,0 277.5,0 277.5,0 283.5,0 289.5,-6 289.5,-12 289.5,-12 289.5,-25 289.5,-25 289.5,-31 283.5,-37 277.5,-37\"/>\n",
       "<text text-anchor=\"middle\" x=\"249.5\" y=\"-14.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">bot_turn</text>\n",
       "</g>\n",
       "<!-- retrieve_relevant_chunks&#45;&gt;bot_turn -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>retrieve_relevant_chunks&#45;&gt;bot_turn</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M243.38,-65.67C242.84,-59.99 242.65,-53.55 242.8,-47.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.3,-47.42 243.39,-37.23 239.31,-47.01 246.3,-47.42\"/>\n",
       "</g>\n",
       "<!-- input__user_query -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>input__user_query</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"238.5,-169 92.5,-169 92.5,-132 238.5,-132 238.5,-169\"/>\n",
       "<text text-anchor=\"middle\" x=\"165.5\" y=\"-146.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">input: user_query</text>\n",
       "</g>\n",
       "<!-- input__user_query&#45;&gt;retrieve_relevant_chunks -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input__user_query&#45;&gt;retrieve_relevant_chunks</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.9,-131.67C198.08,-124.68 208.74,-116.56 218.54,-109.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"220.68,-111.86 226.52,-103.01 216.44,-106.29 220.68,-111.86\"/>\n",
       "</g>\n",
       "<!-- input__lancedb_con -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>input__lancedb_con</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"410.5,-169 256.5,-169 256.5,-132 410.5,-132 410.5,-169\"/>\n",
       "<text text-anchor=\"middle\" x=\"333.5\" y=\"-146.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">input: lancedb_con</text>\n",
       "</g>\n",
       "<!-- input__lancedb_con&#45;&gt;retrieve_relevant_chunks -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>input__lancedb_con&#45;&gt;retrieve_relevant_chunks</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M310.1,-131.67C300.92,-124.68 290.26,-116.56 280.46,-109.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.56,-106.29 272.48,-103.01 278.32,-111.86 282.56,-106.29\"/>\n",
       "</g>\n",
       "<!-- bot_turn&#45;&gt;retrieve_relevant_chunks -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>bot_turn&#45;&gt;retrieve_relevant_chunks</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M255.61,-37.23C256.16,-42.91 256.35,-49.34 256.2,-55.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252.7,-55.49 255.62,-65.67 259.69,-55.89 252.7,-55.49\"/>\n",
       "</g>\n",
       "<!-- input__llm_client -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>input__llm_client</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"133,-103 0,-103 0,-66 133,-66 133,-103\"/>\n",
       "<text text-anchor=\"middle\" x=\"66.5\" y=\"-80.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">input: llm_client</text>\n",
       "</g>\n",
       "<!-- input__llm_client&#45;&gt;bot_turn -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>input__llm_client&#45;&gt;bot_turn</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M116.99,-65.84C142.79,-56.82 174.07,-45.88 199.76,-36.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"201.02,-40.16 209.31,-33.56 198.71,-33.55 201.02,-40.16\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f2626e03c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from burr.core import ApplicationBuilder\n",
    "\n",
    "application = (\n",
    "    ApplicationBuilder()\n",
    "    .with_actions(retrieve_relevant_chunks, bot_turn)\n",
    "    .with_transitions(\n",
    "        (\"retrieve_relevant_chunks\", \"bot_turn\"),\n",
    "        (\"bot_turn\", \"retrieve_relevant_chunks\"),\n",
    "    )\n",
    "    .with_entrypoint(\"retrieve_relevant_chunks\")\n",
    "    .build()\n",
    ")\n",
    "application.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ApplicationBuilder` patterns allows you to add all the features you need for production-readiness without modifying the logic of your agent. In the next few cells we'll add:\n",
    "\n",
    "- a hook to display the bot replies\n",
    "- tracking and storing execution metadata\n",
    "- add OpenTelemetry support\n",
    "\n",
    "To quickly develop an interactive experience in the terminal, we can add a `Hook` that will run after each `step` (i.e., `action`). It will check if the name of the previously completed action is equal to `bot_turn`. If it's the case, the hook prints the most recent message from the state's `chat_history`, in other words, the bot's reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from burr.lifecycle import PostRunStepHook\n",
    "\n",
    "class PrintBotAnswer(PostRunStepHook):\n",
    "    \"\"\"Hook to print the bot's answer\"\"\"\n",
    "    def post_run_step(self, *, state, action, **future_kwargs):\n",
    "        if action.name == \"bot_turn\":\n",
    "            print(\"\\n🤖: \", state[\"chat_history\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we specify via `.with_hooks()` to use the `PrintBotAnswer` hook and via `.with_tracker(..., use_otel_tracing=True)` to track execution and activate OpenTelemetry support. By importing the `opentelemetry.instrumentation` packages for `openai` and `lancedb` and using their `Instrumentor`, we'll be able to track more execution metadata.\n",
    "\n",
    "Also, we create the `OpenAI` client and the `LanceDBConnection` and bind to specific action parameter using the `.bind()` parameter. Notice how it changes the visualization slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"204pt\" height=\"177pt\"\n",
       " viewBox=\"0.00 0.00 204.00 177.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 173)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-173 200,-173 200,4 -4,4\"/>\n",
       "<!-- retrieve_relevant_chunks -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>retrieve_relevant_chunks</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M184,-103C184,-103 12,-103 12,-103 6,-103 0,-97 0,-91 0,-91 0,-78 0,-78 0,-72 6,-66 12,-66 12,-66 184,-66 184,-66 190,-66 196,-72 196,-78 196,-78 196,-91 196,-91 196,-97 190,-103 184,-103\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-80.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">retrieve_relevant_chunks</text>\n",
       "</g>\n",
       "<!-- bot_turn -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>bot_turn</title>\n",
       "<path fill=\"#b4d8e4\" stroke=\"black\" d=\"M126,-37C126,-37 70,-37 70,-37 64,-37 58,-31 58,-25 58,-25 58,-12 58,-12 58,-6 64,0 70,0 70,0 126,0 126,0 132,0 138,-6 138,-12 138,-12 138,-25 138,-25 138,-31 132,-37 126,-37\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-14.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">bot_turn</text>\n",
       "</g>\n",
       "<!-- retrieve_relevant_chunks&#45;&gt;bot_turn -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>retrieve_relevant_chunks&#45;&gt;bot_turn</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M91.88,-65.67C91.34,-59.99 91.15,-53.55 91.3,-47.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"94.8,-47.42 91.89,-37.23 87.81,-47.01 94.8,-47.42\"/>\n",
       "</g>\n",
       "<!-- input__user_query -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>input__user_query</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" stroke-dasharray=\"5,2\" points=\"171,-169 25,-169 25,-132 171,-132 171,-169\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-146.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">input: user_query</text>\n",
       "</g>\n",
       "<!-- input__user_query&#45;&gt;retrieve_relevant_chunks -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input__user_query&#45;&gt;retrieve_relevant_chunks</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98,-131.67C98,-125.99 98,-119.55 98,-113.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"101.5,-113.23 98,-103.23 94.5,-113.23 101.5,-113.23\"/>\n",
       "</g>\n",
       "<!-- bot_turn&#45;&gt;retrieve_relevant_chunks -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>bot_turn&#45;&gt;retrieve_relevant_chunks</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.11,-37.23C104.66,-42.91 104.85,-49.34 104.7,-55.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"101.2,-55.49 104.12,-65.67 108.19,-55.89 101.2,-55.49\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f2626bae550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from burr.core import ApplicationBuilder\n",
    "from opentelemetry.instrumentation.openai import OpenAIInstrumentor\n",
    "from opentelemetry.instrumentation.lancedb import LanceInstrumentor\n",
    "\n",
    "LanceInstrumentor().instrument()\n",
    "OpenAIInstrumentor().instrument()\n",
    "\n",
    "llm_client = openai.OpenAI()\n",
    "lancedb_con = lancedb.connect(os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__URI\"])\n",
    "\n",
    "application = (\n",
    "    ApplicationBuilder()\n",
    "    .with_actions(\n",
    "        retrieve_relevant_chunks.bind(lancedb_con=lancedb_con),\n",
    "        bot_turn.bind(llm_client=llm_client),\n",
    "    )\n",
    "    .with_transitions(\n",
    "        (\"retrieve_relevant_chunks\", \"bot_turn\"),\n",
    "        (\"bot_turn\", \"retrieve_relevant_chunks\"),\n",
    "    )\n",
    "    .with_entrypoint(\"retrieve_relevant_chunks\")\n",
    "    .with_tracker(\"local\", project=\"substack-rag\", use_otel_tracing=True)\n",
    "    .with_hooks(PrintBotAnswer())\n",
    "    .build()\n",
    ")\n",
    "application.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Launch the `Application`\n",
    "Finally, we start the application in a `while` loop, allowing it to run until we exit by inputting `quit` or `q`. We use `application.run()` and specify to halt after the action `bot_turn` to wait for the user's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the Burr application in a `while` loop\n",
    "print(\"\\n## Lauching RAG application ##\")\n",
    "user_query = input(\"\\nAsk something or type `quit/q` to exit: \")\n",
    "\n",
    "while True:\n",
    "    if user_query.lower() in [\"quit\", \"q\"]:\n",
    "        break\n",
    "\n",
    "    _, _, _ = application.run(\n",
    "        halt_after=[\"bot_turn\"],\n",
    "        inputs={\"user_query\": user_query},\n",
    "    )\n",
    "    user_query = input(\"\\nAsk something or type `quit/q` to exit: \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
